It is expensive that is for sure. I'd say I got to most of these places before I was like out on my own. Like my parents took us a good amount of places, so that was definitely a benefit. Yeah. Well, the plane tickets, it's like, you go somewhere, like, I don't know, Texas to see my friend, and that was, like, $200. And I was like, that's not even like any other thing yet. That's just Yeah, sure. You know what we did was a lot of road trips before gas was crazy expensive and I was let all we did so many road trips and like hours and hours and hours in the car, but I'd say I hit like probably 10 or 15 of these states on road trips. So keeping it, it cheap. Well, I'm excited for you to talk to Tuin. He'll be on in just a little bit, but I gave him a little bit of like a summary of what you were interested in. And I think he's going to be a great resource for you. Okay, awesome. And then Jared, Jared is another AI reporter, and he's going to be joining his wife, that's all right. Perfect, yeah, of course. Okay, cool. We're in New York are you? I'm in upstate New York right now. That's where my family's from. So, yeah, Jared is in New York City, so he's probably at the office. I, I lived in Williamsburg for two years in Brooklyn. Oh, nice. Yeah, we lived there for, let's see, it was like 2022 to 2024 for my husband's job. So we like went and like left LA, went to New York for a couple of years, and then we were like, ooh, seasons. I don't know if we need these. He's from Arizona. I'm from LA. I was like, I don't even have a winter coat. this is cold. Where are you based right now? Los Angeles. Oh, nice, nice. This is how families gear. I never made it to Upstate. Actually, that's not true. We went to Beacon. Hey, J. Hey, there. Can you hear me? Yep. Not and clear. Hey, sorry for being late. There's a a dearth of phone booths in the office, but good to be. Well, you're not late because our special guest is later than you. So for all kinds of purposes, you are on time. In that case, I will leave. I'll give him a quick tang, but he should be on in just a minute. They also have a phone booth Dirth, so there we go. I hate Tan, we were just talking about phone booths and offices. Were you able to spot one this morning? I I was running around trying to find one. Yeah. I got one. I'm. Well, I will leave you, Jasmine, and Jared to chat with Tuan. I'll go off camera and be a fly on the wall. But I'm very excited for you to meet him and talk bass 10 and open source. So take it away. Yeah, absolutely. I'll just do a quick introduction. So my name's Jasmine. I'm an air reporter with NBC News And for this story, we're trying to understand the open kind of closed source landscape, understanding the relationship between those two. We're particularly interested in some of the models coming out of Chinese companies, so like Quen, deep seek. I saw you guys also have Kimmy GLM. They're really really seem to be very popular with developers that we've talked to. So especially curious, what you're seeing there. And if you and Jared, do you want to introduce yourself next? But yeah, if we could go through around, that'd be lovely. Sure, absolutely. My name is Jared. Lovely to meet you. Thanks so much for taking the time. I'm also an AI reporter here. Co pretty much everything under the AI Sun. And I'll leave it there. I think Jasmine covered a great questions we were interested in., Amazing. I'm T, I'm the CEO of one of the copes 10, and we do AI infrastructure, focus almost exclusively on inference of customeroles models. And so, you know, we regard a lot of the fastest growing companies up today Co or a Bridge, open evidence, clear gamma, amongst a bunch of others. Awesome, Yeah, I guess, like, just to kick it off, what has open source adoption looked like? And how is that trend been changing? Yeah, look, I think, you know, I maybe we just answer to a question directly, but I was like, yeah, like, it's definitely on, like, good and on the up and up, I think. I think a few years ago, a few years ago, when the Tachi BT Mentabit, I think you have to really squint, I think you have to really squ squint to see, hey, what open to have a chance of being as good as Kosos. And I think over our three has gone with every success of ding successive generation of models, kind of the gap has gone smaller, and not only has the gap got smaller, it's that the the tain lag between when you know there is a model of aimate capability in the open source, that timeline has gotten shorter as well. That's kind of what we see we developers as well, where it's like, you know, I think all of our customers use the combination of open and close lost models, or the majority of our customers use a combination of open and close lost models, and I think, like, there's kind of this journey where it's like, hey, you start with close lost models, you go for power capability and speed at some point, data privacy cost of performance, customization, all those things, like tunability, these all become real issues and I think that drives adoption and that kind of what we're doing in our custom-based customer base. And I think with every release of a new model that kind of goes up. So whether that's, you Deep Seek at the beginning of, I mean, Lava 3 was probably the, you know, like originally created the most bones, buzzed than Deep seeing B3. then I think, the biggest honesty, like the biggest driver has been Cowen. Like, Quinn Quinn just, you know, a very powerful model with a lot of customization ability to customize it and that it's not just a family or model. it's not one model, it's a family of models that are all amazing. And so we see that with almost all of our custom are using some some some parents of these models or models inspired by this model at the very list. What's driving this move? I mean, historically, right, like, there was Bloomberg GPT and they're like, we're gonna to find two in our own model. And then it on their, you know, nice proprietary Bloomberg data and it got totally trounced by like GPT 35, 37 on, you know, financial questions. So I guess I'm curious, like, what's, what's making this, like, more possible or unlocking? I guess, like open source use for companies today? Yeah, I think it's a few things. So I't the biggest one is, hey, I do need the most powerful model in the world to do every task. I think that's like, just like, a very valid question then. Needs to be honest, and the answer is usually no. The answerers usually know that. So that's one, which is like, hey, you just don't need such an expensive, big model or like, such a big hammer, to solve these kind of. Like, you know, if you if you were doing stuff like automplete for tap completion, if you're doing stuff like, if you're creating a model, if you're creat a model that's, you know, trying to classify which building code needs that a medical record needs to to you, you don't need, you know, the whole corpus of the internet there. So I think that's one where's like, hey, it's capability is not necessary. The tune three biggest ones are, one is this like data privacy security, being able to run these yourself as opposed to in the black box way that you get with the foundation model companies, and that also opens the door to be able to tune them, fine tune them. I mean, I think we've got really good at RL, at reinforcement learning and being able to find tune these things, especially with direct preference data. from customers. But I think the far and away biggest honesty is that assuming you can get approximate quality, approximately the right quality, you want these models to run as fast as possible. I think the ability to do that, the way to get models to run fast is to tune like your infrastructure deployments exactly for your use case. And you just can't do that. with close health models, because it's bit of a one size fits all, and the last piece is like, a lot of these cost the companies that they're using over to drop big, spending $10 to million on it. And I think there's just a bit of like a sustainability question as well, which is like, hey, how do we actually create gross profit? And that is by not using the biggest strongest, most powerful model at any time, but going to these equally, like really, really good models, that, you know, are a fraction of the siz or can be tuned or, you have a lot more control of the cost server that make it a lot more centated business. Do you think some of this, then, is like an expansion of the imagination just companies getting more familiar with these tools and their actual needs? I mean, it is like the ecosystems crazy being created around it, right? Like that's like the e emails ecosystem, or the reinforcement learning ecosystem all honestly, like the systems of companies like us that are making it easy to run these these models. So like, I think it's a really good example of this would be like, hey, like three years ago, if you wanted to run QN in production at some scale, you know, you'd need a lot of help. You need a lot of help, and you'd probably need to stop a team and do a lot of like solve a lot of problems with subtract. Today, there are companies like BT that help you reduce their infrastructure burden while allowing you to run the performantly constitfficiently and all those good things. So I think, yes, I think the answer is yes. Like, you know, you very much, as we as we are getting more mature, I think two things are clear one. It's like, what do we need? What primitives are the application layer need? from an infrastructure perspective? And I think those exists kind of off the shelf warm. Interesting, yeah, no, I was curious because you said, like, you were talking about, you know, it's cheaper to run the close sorry, open source models. But for us, I remember, like, we tried to, we wanted to like host an endpoint that served like Falcon 80B and they were like, we're not going to do that. Yeah. Yeah. Interesting. Yeah. I guess what do you think the balance looks like going forward then? Are we going to shift more towards open source? Are they going to, do you think it'll one day overtake like what the labs are offering? Like, how do you think this is going to evolve? Yeah, like, I. You know, I grew up. I I grew up in Australia and there was this this ad for tacos on TV where I do on softft show or Crispy show and there's a kid it's just like, why not both. I feel like that's how I feel about open open closed stores, which is I think the reality is the reality is that like most companies and like almost every company we talked to stadi as a combination of closed and open sours. And I think it's just like, hey, what is the use case? What is the what is like the performance tolerance? What's to cost tolerance? What are the data of privacy concerns? And you just like, you know, you need both. I think. over the time, where I think you'll see is that, as I said, the capabilities were approximately match and, like, I think closelace is actually a very, very important necessary part of the ecosystem, because, you know, they can do like, open source just tends to be a little slower than cols because you know there's a lot more oversight to some extent of a community. These coles sorts of people can just run out of problems solve them, and I think, you, they'll put at times they were really push the boundaries and the open support just be catching up. And I do think they'll catch up. I think the time that they'll take to catch up is going to be lower, Laura, Laura. And like, you know, for example, you said something at the beginning of this. around, you said something at the beginning of around Is there like the be start of like the Quinn Kimi KLM teaching? Like, the reason why, you know, make all of it's like, the reason why it's so it's so palpable is because the closest models are starting to stagnate a little on how much better they're getting like the GPD board to the GPT vibe just wasn't that big. And so you're like, oh, look, there's other open source options available. I think both are very important. Yeah, no, thanks, too. Cool. Yeah, if I could just hop in, I'm curious about, well, I'm curious about a couple things. One, in terms of like selecting which model you use on the open source side, I think you talked a little bit about it, that, you know, QN is just very, you know, incredibly powerful, and it seems like a go to option for a lot of people in this space. Something that we're kind of like curious to explore is, you know, the difference between the Chinese open source, open weight ecosystem and the U.S ecosystem, I mean, does that factor into your choice at all in terms of like, which model you use? I mean, there's Omo out of the Allen Institute, you know, Lama, theoretically, still exists, but just curious, you know, your overall take on that, that side of things. Yes. Yeah. Look, I think if there were.. I think if there were options to run American models or just like, mobile models, there would people would prefer those, right? Like, I think that's, you know, why, if they're equal, you know, there is allegiance to some extent. That being said, I think there is a gap today from a capability perspective. And so, I think that's like really like one of the the is not the right word. Like, it's like one of the things that it's so important for American open source models to get better, I think, for that reason, because otherwise, like, a lot of this stuff, we would not because it' anything wrong with building stuff with models from where all over the world. It's just like, hey, you want, like a thriving ecosystem of models getting better because I think these models getting better just to beet other people in the same markets to get better. So it's no, it's not like, to me, it's not a surprise that's not just one amazing opens model that there's four or five coming from China. And I mean they just pushing each other to get better. And I think we need to rekindle that to some extent. How do people choose? Look, I think, like, capability is still the number one thing people choose on. Like, the reason why, like, open to a spend with L two years ago was because open T Sm was just one. That's good. That's because Source models. And so, like, I think that's what Chan has done really well, like, it crossed many modalities across many modalities, across, you know, almost for like some time period. Now they're just putting out really, really capable models. And I think that's how it develops is to choose what to use, which is, hey, how, like, what capability do I get? What does my ability to be able to change that model and change this behavior and, you know, tune it to my extent but I think the third one is cost to some extent. Like, it's pretty crazy, right? That, you know, TPT over says, you know, we were one launch partneristan, like a great model, but like the demand for something like a Quinn or GLM it actually just so much higher than the GPT said, I think that's the cap it's the capability thing. What is your typical customer look like and like, what's an example of something they might be trying to do? Yeah, look, we ser the AI Native segment, so you could think about, you know, really, like, any of these, like, very, very fasting companies, anything from, like, summarization to generation of synthesis to code, work, to a lot of like, there's a lot of voice. Some people are doing, people building voice agent. So like the way I would say it is like, if you look at, you know, all the passes growing companies in the world and you think about what they are doing for their customers in the applayer, baseass Cent is probably powering of something that you'll use and the last 24 hours. And so, you know, whether that's, you know, copies like a bridge in open evidence where, you know, they're could build a lot of custom stuff, whether it's company be like Gamma that's done like like slide creation, or whether it's even a company like Mirage or captions who you just do code captions, which is doing video gen. It's kind of like your whole slate of Gen AI applications on a running a base 10. Are there any, like, more traditional, like, enterprise, like, I don't know, like the Home Depot or something like that? Yeah, we have a variety of enterprises. You know, it is still early for them, and I think a lot of there are just a lot more experimental. And I think they have very different needs as well. Like, like our primary focus is that AI native AI native categries today. I'm curious, when you say different needs, like, what can you give me a sense of what that means? Yeah, look, I mean, they have and like, look, we have built our platforms to support it, and like, that's why we end up, like, spending a bunch of time with them is like, they need to run stuff all inside their VPCs. You know, like, they don't really want to use, you know, like AlCouds. They have different performances requirements. They're generally a bit slower in terms of how they ad adopt software. You know, they have a lot of. Yeah, and so it's cous typical enterprise. Dunes, it's just like, it's just a different terror requirement. And I'd say like AI budgets right now and the Enterprise are either still pretty experimental, I'd say, I think there's like a small set, small set of kind of the is a small set of customers that are really pushing the envelope for the most part, like a lot of the purchasing is still at the application layer and, you know, they're just taking stuff that works off the shelf for them as opposed to, you know, standing up open source bottles themselves with reliable infrastructure running inside their LPCs, which I think still is quite a bit of a lift for that. And if I can hop in, thank you all so much for all this, it's really fascinating. K to know, going back to something you mentioned before, on the clothes source side, you know, you say you don't need the world's most powerful model to run, you know, everything to be involved in every single task. And I think you gave some examples of, you know, tasks that like autocomplete or, you know, looking at billing codes that you might use an open source model for. But when might you revert or, you know, consult, lean on those close source models? What are some examples of things where you still want, you know, that raw power? Yeah, like, so search you beats that. You know, when you have, like, open ended questions or, like, really creative tasks, like getting that's where they really shine to some sense, I think they're really good at, you know. I don't know how you guys are changing. I know how you guys are changing, how you're using these tools, but it's interesting, right? Because, like, they have like, more more access to the internet as well. And that kind of changes mind relationship with, you know, like, I use that instead of Google, I probably want to do, like, a research stuff that I use them. And I think that is like, you know, where they're capability really shines. It's the ability to do like, you know, to kind of go and crawl into it and bring it all together, and really use that very, very wide net of knowledge that they've been trained on together with like the context they're gathering. But I think that's like, my argument would be like, that's a little bit more creative than this narrower, like, you know, like, you know, if I go to my ch GPT and ask the question, that I ask, you know, it will be, you know, like I was asking for analysis. I was asking for an analysis of, like, should I buy this stock? And I was just and I was having like, debate with it. But that's like, you know, it's a little bit more creative. It's not just, like, a, heyey, do this one task." Or like, the Godrail. It doesn't doesn't need You almost want to have funeral Godrailails in that case, so it can come up with something real holistic. That's so interesting. You talked about consulting AI. There's a piece someone wrote about the end of Know Nothing customer. It really reminded me of this.. Yeah, I mean, not to pontificate, but, like, I'm curious what you think the broader economic impact in thisist will be as someone who has that perspective of like, who's using this and like where it's kind of touching. Are you to talk about AI in general? Are you about bottles? Yeah, just in general. Yeah, Yeah, yeah, Oh, I'd love to particificate on that. That's That's a great grade. Look, like, I think we're, at least for a week and see what we can see, in the market, it feels like it's incredibly incredibly early. And like, I say that as like, you know, when you go into spend time with Enterprises right now, it's like 999% of the value is still to be unlocked. And so, you know, when you take down the case and you take the fact that, hey, like, if you look at the fet, like the copies that, you know, you know, that you know in this like growing back of AI native couple if you think about how how you get them they are. you know, it's like one, two to three years old all the most part. Maybe like one to four years old, might be like, like, might be conservative. It just feels so, so early, both on the early stage side and from like all the copies that will be created and from Enterprise side. So, like, my, if you were to tell me that the impact of AI on economic intact of AI was, you, a thousand or 10,000 times greater. than what we have seen already. I don't think I'd flint in that. That to me, seems obvious. And you know, that's very, very self-serving, too. But that's very, very self- serving, too, but, you know, but it feels like it's just going to be about it. I mean, when we see this, like just in terms of like the productivity games we get from stuff like code, you know, even things like, how long does it take me to do some of these synthesis tasks or, you know, how I, like I sent in voice notes to people using using my phone a lot more because of the speech attacks translate transliterationcription is a lot better. It does seem like we're just creating these big marks, kind of across society. And we're yet to see kind of a compounded effect of what happened when all these things come together over a long period of time. What's like one example of like opportunity that has yet to be unlocked? Yeah, I do a question. I mean, I think if you go to spend time in, like, healthcare insurance and financial service and even, like, legal stuff, it's like, just like, this is so much crop to work still it's just like, you know, the amount the amount of jobs and not even jobs, the amount of people that, you know, are doing a lot of manual work, just moving down around. See, all that stuff seems like very ripe for like, like giving people to the palace from an AI perspective. I think when you go and talk to enterprises, you know, I'd say like, if you go and think of how much, how much voices being, like, how many phone calls there are and how how big a part, like voices like the human API layer to some extent and like how little voice AI has taken over that. Like, you know, it just does seem like the opportunities like on the voice side are, like, you know, just being started, especially when you start to looping like the agantic stuff on top of, which is like the ability to go back and forth and gather information and then go back and forth again. Yeah. Interesting. I'm just here I just out of curiosity, too. Like, do you use, like, what kinds of models do you use in your own life? Like, do you use open source models, closed, any favorites? I think, like, I think the model that's, like, really, really underrated, but is used a lot, is Whisper, which is like, you know, it's like OG open source, speech to text model that it's still, you know, very, very, very good. I can tell you a bunch of stuff. I use I used this product called flow whisper flow, which is it's basically like I just hold down the function key and I narrate and kind of replace my keyboard. I could communicate to it in natural language, which I think is very cool. Wow. You know, So I could say, hey, actually, not that, or I replace Monday with Tuesday and it goes and makes those changes. which is very cool. I just, obviously Chad GPT a lot. We K users here. They use all sorts of models under the hood. You know, we use t open code, which is, you know, which actually hops into GLM or people use that while with GLM. And so, you know, I can't use it. I use, you know, the notion meetings stick now where it's like basically transcribes the meetings a lot. Yeah, it's kind of everywhere. We just gamma to create our slide decks. Yeah, I feel like it's like kind of, you know, really taking care of, but like school. All right. I'm just taking you over, like, small things without us realizing to some extent. Interesting. Uh, Jared, did you.. Yeah, yeah, yeah. Um, maybe if I can jump in with one last question, I have a heart stop at 12:30 to just have to jump, but curious to know more about like how you see, like the economic impact of open source specifically, and yet your broad thoughts there, and I'm sure you're very plugged in with, you know, others in the ecosystem in the bay, you know, we're based out all the way in New York, so it's slightly less in touch with, you know, what people are really doing. But curious, yeah, on the economic impact, if you have any thoughts there. Yeah, we'll source. Yeah, look, I think what it opens all like allow? Like, faster, cheaper, faster cheaper, more, like, governing, better governance to some extent. And like, it just seems massive, right? Like, I didn't, like, you were driving down the cost of things, you're making them faster, you're allowing people to run them inside their own premises like, with more data privacy and security, posture around it. It seems like that would be an accelerant to bringing customers online, because of the data privacy stuff, especially in this more regulated industries. But I think more importantly, I think, as it dries down the cost of inference, because you have more control over those things, like, what will happen is, it said Jon's Paradox, right, which is like, like the reducing the consual drive Morfords. And so it seems like opens those walls are massive accelerant to me of like how AI, what kind of like, you know, really start to like transform so many organizations and how they work and whatnot. And even like maybe creation of new organizations.. And just a quick follow, did you, I think you mentioned that you worked with curseor a little bit, and they use all sorts of different models under the hood. Do you have a contact there? Do you know, are they also using like open source pretty robustly? I think that's something, just because cursors you know, so widely used in the startup ecosystem, I think we're really curious to know what they're doing as well. Yeah, I'm not really sure, you, I think like, you know Ka is such a powerful tool, and if you go look at like the drop down, like, you could choose the model you want to use, and there's all sorts of models, and you can even bring your own models there. And so, you know, the, like, it's a, um, it's so powerful what they, what, you know, the superpowers they've given and a lot of ways, actually, what's interesting is the ability, the way that they kind of like without without seeing so exply commodetizing on the ling model, because it turns into a dropdown and it open source models and there are closed-source models in there. They've got their own, I think they've got their own stuff there, as well. You know, like, it's it's it's some really cool stuff there. Yeah, Jared, haven't you been trying to get in touch with someone at Cursor? Yeah, they have been slow and non responsive. So, I don't know, do you work with someone there? Yeah, who might be interested. They were Yeah, like, you know, I think they're busy. We're all busy. Yeah. Yeah. Yeah, well, with love an intro, if you can. You'd be open to it. I guess, like more specifically, I mean, so there's all this talk of like the AI bubble, right? Where they're like, oh, like open AI and Drophic are profping up large sectors of the economy, whether you agree with that or not. Like, this is just something that, you know, like, we're hearing a lot as, I guess, like reporters. And we're trying to understand it. Like, what happens then if you have open source companies, like you have like a Quen who's providing this, like for free. you know, to some extent. Do you have thoughts there on, like, the nature of that relationship going forward? I understand the question. It's just like, hey, like, open air dropping is so big. Like, does they value go down? Because of, like, the open source models that are cheaper to run to some extent? Yeah, like, will it cannibalize, like, eat their lunch, basically. Well. It just seems like the opportunity, like, you know, I think to something like, I think like some of the narrative around, like, you know, who, like. I personally, I can reject a lot of the narrative around, like, you know.
