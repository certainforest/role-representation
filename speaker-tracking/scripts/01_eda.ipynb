{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273670e1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2d4b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd \n",
    "import re\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = 'mps'\n",
    "\n",
    "# pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f2cb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transcripts\n",
    "dir = Path('../data/transcripts')\n",
    "doc_paths = sorted(dir.glob('*.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7819ce",
   "metadata": {},
   "source": [
    "# Eval\n",
    "\"Common sense\" checks using openrouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff0bd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create string representing a single conversation\n",
    "doc = doc_paths[0]\n",
    "\n",
    "with doc.open('r', encoding = 'utf-8') as f:\n",
    "    lines = [\" \".join(line.split()) for line in f if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5eff98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to think more abt. prompting strategy...lot of variance...\n",
    "task = '''This transcript contains speaker labels. Some labels refer to the same real person.\n",
    "\n",
    "Tasks:\n",
    "1) How many unique real participants are there?\n",
    "2) Which speaker labels are duplicates of the same person?\n",
    "3) For each duplicate, say which label it should be merged into.\n",
    "4) Give one short sentence describing each real participant.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1411908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s a detailed answer to your four tasks based on the provided transcript:\n",
      "\n",
      "---\n",
      "\n",
      "### 1) How many unique real participants are there?\n",
      "\n",
      "There are **three unique real participants** in the transcript:\n",
      "\n",
      "- **Jasmine** (the interviewer/reporter from NBC News)\n",
      "- **Speaker 4 / Lynn** (the CEO and co-founder of Fireworks, also referred to as \"Lynn\" by Jasmine at the end)\n",
      "- **Speaker 1** (whose identity is not explicitly named, but appears to be someone else in the conversation, possibly a colleague of Jasmine or part of her team)\n",
      "\n",
      "However, upon close reading, \"Speaker 1\" is likely the same as Jasmine, based on the context and conversational flow. Jasmine is the one initiating and leading the interview, and \"Speaker 1\" seems to be her speaking at several points (e.g., \"Speaker 1 12:33:04 ... we represent fireworks...\"). The transcript labels may be inconsistent, but the content suggests only two main people are speaking before Lynn joins: Jasmine and possibly another person (Speaker 2 and Speaker 3 briefly chime in at the start, but their lines are brief and seem like side comments or background chatter, not main participants in the interview).\n",
      "\n",
      "But let's break it down:\n",
      "\n",
      "- **Jasmine** (clearly identified)\n",
      "- **Lynn** (identified as CEO of Fireworks, also called \"Speaker 4\")\n",
      "- **Speaker 2** and **Speaker 3** appear only at the very beginning with casual conversation, but do not participate in the main interview. Their lines are short and not part of the formal discussion.\n",
      "- **Speaker 1** is likely Jasmine herself, given the context and the fact that Jasmine is the one asking questions and leading the conversation after Lynn joins.\n",
      "\n",
      "**Therefore, the unique real participants in the main interview are:**\n",
      "- Jasmine\n",
      "- Lynn (Speaker 4)\n",
      "\n",
      "But if we count all who speak at any point:\n",
      "- Jasmine (Speaker 1 and Jasmine label)\n",
      "- Speaker 2 (unidentified, possibly a bystander)\n",
      "- Speaker 3 (unidentified, possibly a bystander)\n",
      "- Lynn (Speaker 4)\n",
      "\n",
      "But only Jasmine and Lynn are meaningfully engaged in the interview.\n",
      "\n",
      "**Final answer:**  \n",
      "There are **2 unique real participants** in the main interview (Jasmine and Lynn).  \n",
      "If including the background speakers, there may be up to 4, but only 2 are meaningfully engaged.\n",
      "\n",
      "---\n",
      "\n",
      "### 2) Which speaker labels are duplicates of the same person?\n",
      "\n",
      "- **Speaker 1** and **Jasmine** are the same person. Jasmine is explicitly named and is the interviewer. The \"Speaker 1\" label is used for her at the beginning before her name is introduced.\n",
      "- **Speaker 4** is Lynn, the CEO of Fireworks.\n",
      "\n",
      "**So:**\n",
      "- \"Speaker 1\" is a duplicate label for Jasmine.\n",
      "- \"Jasmine\" and \"Speaker 1\" refer to the same person.\n",
      "- \"Speaker 4\" is Lynn.\n",
      "\n",
      "---\n",
      "\n",
      "### 3) For each duplicate, say which label it should be merged into.\n",
      "\n",
      "- **Speaker 1** should be merged into **Jasmine** (since Jasmine is the named interviewer and \"Speaker 1\" is just a generic label for her at the start).\n",
      "\n",
      "---\n",
      "\n",
      "### 4) Give one short sentence describing each real participant:\n",
      "\n",
      "- **Jasmine**: An AI reporter at NBC News, conducting an interview about open source models and AI infrastructure.\n",
      "- **Lynn**: CEO and co-founder of Fireworks, an AI inference platform company, with extensive experience in AI infrastructure and open source projects like PyTorch.\n",
      "\n",
      "(Optional: If you want to include the background speakers, but they are not meaningfully identified or engaged in the interview.)\n",
      "\n",
      "---\n",
      "\n",
      "**Summary Table:**\n",
      "\n",
      "| Label(s)         | Real Name | Description |\n",
      "|------------------|-----------|-------------|\n",
      "| Speaker 1 / Jasmine | Jasmine | AI reporter at NBC News, interviewer |\n",
      "| Speaker 4        | Lynn      | CEO and co-founder of Fireworks, AI infrastructure expert |\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you want a more detailed breakdown or if you want to include the background speakers as participants.\n"
     ]
    }
   ],
   "source": [
    "messages = [{'role': 'user', 'content': f'{task}: {conversation}'}]\n",
    "\n",
    "response, reasoning, refusal, provider = send_openrouter_request(messages, model = 'allenai/olmo-3.1-32b-instruct')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33eed30",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "Creating a speaker:token mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "840387d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure message dictionary\n",
    "time = re.compile(r'\\d{2}:\\d{2}:\\d{2}')\n",
    "\n",
    "turns, speaker, msgs = [], None, []\n",
    "\n",
    "for ln in lines:\n",
    "    if time.search(ln):\n",
    "        if speaker and msgs:\n",
    "            speaker = time.sub('', speaker).strip()\n",
    "            turns.append({'speaker': speaker, 'text': ' '.join(msgs)})\n",
    "        speaker, msgs = ln, []\n",
    "    else:\n",
    "        if speaker:\n",
    "            msgs.append(ln)\n",
    "\n",
    "if speaker and msgs:\n",
    "    speaker = time.sub('', speaker).strip()\n",
    "    turns.append({\"speaker\": speaker, \"text\": \" \".join(msgs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46e57edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>Lin</td>\n",
       "      <td>across</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>Lin</td>\n",
       "      <td>industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>Lin</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>Lin</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>Lin</td>\n",
       "      <td>more.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>much,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Jasmine</td>\n",
       "      <td>appreciate.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      speaker         word\n",
       "4085      Lin       across\n",
       "4086      Lin     industry\n",
       "4087      Lin           to\n",
       "4088      Lin  standardize\n",
       "4089      Lin        more.\n",
       "...       ...          ...\n",
       "4180  Jasmine           so\n",
       "4181  Jasmine        much,\n",
       "4182  Jasmine          and\n",
       "4183  Jasmine       really\n",
       "4184  Jasmine  appreciate.\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decompose to word level\n",
    "words = []\n",
    "for t in turns:\n",
    "    # print(t['text'])\n",
    "    for w in t['text'].split():\n",
    "        words.append({'speaker': t['speaker'], 'word': w})\n",
    "\n",
    "df = pd.DataFrame(words)\n",
    "\n",
    "df.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368c90ea",
   "metadata": {},
   "source": [
    "# Activations\n",
    "!important: make sure you have required mem, especially if running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60677a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 15 files: 100%|██████████| 15/15 [17:47<00:00, 71.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/jasminecui/.cache/huggingface/hub/models--allenai--Olmo-3-7B-Instruct/snapshots/096bb5469fe34348bc88d851a69edb3bf6f40df4'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "# mid = 'allenai/Olmo-3-7B-Instruct'\n",
    "# snapshot_download(\n",
    "#             repo_id = mid\n",
    "            \n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 355/355 [00:00<00:00, 2907.19it/s, Materializing param=model.norm.weight]                                \n"
     ]
    }
   ],
   "source": [
    "# load tokenizer + model\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/Olmo-3-7B-Instruct', local_files_only = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Olmo-3-7B-Instruct',\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    local_files_only = True\n",
    "    ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78b205f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fast: True\n",
      "has_chat_template: True\n"
     ]
    }
   ],
   "source": [
    "print(\"is_fast:\", tokenizer.is_fast)\n",
    "print(\"has_chat_template:\", tokenizer.chat_template is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b14cfe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are a helpful function-calling AI assistant. You do not currently have access to any functions. <functions></functions>\n",
      "user\n",
      "Tell me a fun fact about fish\n",
      "assistant\n",
      "Sure! Here’s a fun fact: **Some species of fish can regrow their fins and even parts of their tails if they lose them during an encounter with a predator or while swimming through rough water.** This ability is called **fin regeneration**,\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Tell me a fun fact about fish\"}]\n",
    "\n",
    "enc = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "# enc is likely a BatchEncoding; pass the tensor explicitly:\n",
    "input_ids = enc[\"input_ids\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=50,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2f8017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Olmo3ForCausalLM(\n",
       "  (model): Olmo3Model(\n",
       "    (embed_tokens): Embedding(100278, 4096, padding_idx=100277)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x Olmo3DecoderLayer(\n",
       "        (self_attn): Olmo3Attention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Olmo3RMSNorm((4096,), eps=1e-06)\n",
       "          (k_norm): Olmo3RMSNorm((4096,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Olmo3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (post_attention_layernorm): Olmo3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Olmo3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Olmo3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): Olmo3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=100278, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
